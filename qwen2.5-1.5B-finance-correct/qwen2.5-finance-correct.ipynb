{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f219b642-9dea-463d-ab0a-8442ecce8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory before: 0.00GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Clear GPU memory at start\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"GPU memory before: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "\n",
    "# Set memory management environment variable\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690e6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msohanv\u001b[0m (\u001b[33msohv\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0ca8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/precog-sv/qwen2.5-1.5B-finance-correct/wandb/run-20250904_121347-hl0tne6a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sohv/qwen-big-finance-correct/runs/hl0tne6a' target=\"_blank\">qwen-big-finance-correct-run</a></strong> to <a href='https://wandb.ai/sohv/qwen-big-finance-correct' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sohv/qwen-big-finance-correct' target=\"_blank\">https://wandb.ai/sohv/qwen-big-finance-correct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sohv/qwen-big-finance-correct/runs/hl0tne6a' target=\"_blank\">https://wandb.ai/sohv/qwen-big-finance-correct/runs/hl0tne6a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sohv/qwen-big-finance-correct/runs/hl0tne6a?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ce3585c8150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_project = \"qwen-big-finance-correct\"\n",
    "wandb_run_name = \"qwen-big-finance-correct-run\"\n",
    "\n",
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    name=wandb_run_name,\n",
    "    mode=\"online\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bd9a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 6000 examples [00:00, 218254.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/finance_correct.jsonl\"\n",
    "dataset = load_dataset(\"json\", data_files=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614ae906",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = dataset[\"train\"].train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "dataset = {\"train\": split[\"train\"], \"validation\": split[\"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede46496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5400/5400 [00:00<00:00, 8652.02 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 8940.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5400\n",
      "Eval dataset size: 600\n",
      "Sample text field: <|system|>\n",
      "You are ChatGPT, a large language model trained by OpenAI.\n",
      "<|user|>\n",
      "I'm a small business owner keen to invest sustainably, especially in green bonds and renewable assets. What innovative st...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset to create a 'text' field instead of using formatting_func\n",
    "def preprocess_example(example):\n",
    "    \"\"\"Convert the conversation format to a single text field\"\"\"\n",
    "    messages = example[\"messages\"]\n",
    "    formatted_text = \"\"\n",
    "    \n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    " \n",
    "        # Extract text content safely\n",
    "        if isinstance(content, dict) and \"parts\" in content:\n",
    "            parts = content[\"parts\"]\n",
    "            if isinstance(parts, list):\n",
    "                content_text = \" \".join(str(part) for part in parts)\n",
    "            else:\n",
    "                content_text = str(parts)\n",
    "        else:\n",
    "            content_text = str(content)\n",
    "        \n",
    "        # Format based on role\n",
    "        if role == \"system\":\n",
    "            formatted_text += f\"<|system|>\\n{content_text}\\n\"\n",
    "        elif role == \"user\":\n",
    "            formatted_text += f\"<|user|>\\n{content_text}\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            formatted_text += f\"<|assistant|>\\n{content_text}\\n\"\n",
    "    \n",
    "    return {\"text\": formatted_text.strip()}\n",
    "\n",
    "# Apply preprocessing to create text field\n",
    "print(\"Preprocessing dataset...\")\n",
    "train_dataset = dataset[\"train\"].map(preprocess_example, remove_columns=dataset[\"train\"].column_names)\n",
    "eval_dataset = dataset[\"validation\"].map(preprocess_example, remove_columns=dataset[\"validation\"].column_names)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "print(f\"Sample text field: {train_dataset[0]['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde3020b-d2a6-410e-ad34-66fb21272699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] BF16 supported: True. Loading dtype: torch.bfloat16\n",
      "[INFO] GPU total: 23.5GB, allocated: 0.0GB, free: 23.5GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GPU memory after model loading: 2.9GB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B\"\n",
    "\n",
    "supports_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "load_dtype = torch.bfloat16 if supports_bf16 else torch.float32\n",
    "\n",
    "print(f\"[INFO] BF16 supported: {supports_bf16}. Loading dtype: {load_dtype}\")\n",
    "\n",
    "# Check available GPU memory before loading\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    free_memory = gpu_memory - allocated_memory\n",
    "    print(f\"[INFO] GPU total: {gpu_memory:.1f}GB, allocated: {allocated_memory:.1f}GB, free: {free_memory:.1f}GB\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=load_dtype,\n",
    "    device_map=\"auto\",                    # Automatically distribute layers across devices\n",
    "    offload_folder=\"./offload\",           # Disk offload folder for weights\n",
    "    low_cpu_mem_usage=True,              # Reduce CPU memory usage during loading\n",
    "    trust_remote_code=True,\n",
    "    # max_memory={0: \"10GB\", \"cpu\": \"30GB\"},  # Uncomment to limit GPU usage\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Check memory after model loading\n",
    "if torch.cuda.is_available():\n",
    "    allocated_after = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"[INFO] GPU memory after model loading: {allocated_after:.1f}GB\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c20041",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=\"/home/models/finetuned_qwen2.5-finance-correct/\",\n",
    "    run_name=wandb_run_name,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16= not supports_bf16,\n",
    "    bf16=supports_bf16,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"wandb\",\n",
    "    logging_dir=\"/home/logs/qwen2.5-finance-correct\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    seed=42,\n",
    "    push_to_hub=False,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d255ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Sample preprocessed training strings:\n",
      "<|system|>\n",
      "You are ChatGPT, a large language model trained by OpenAI.\n",
      "<|user|>\n",
      "I'm a small business owner keen to invest sustainably, especially in green bonds and renewable assets. What innovative strategies can I explore to grow my capital while supporting eco-friendly initiatives?\n",
      "<|assistant|>\n",
      "As a small business owner interested in sustainable investments, consider diversifying your portfolio with funds dedicated to renewable energy projects and green bonds. Explore opportunities in community solar initiatives, where you can invest in solar farms that provide energy to local areas. Additionally, look into Sustainable Investment Funds or ETFs that focus on companies with strong environmental, social, and governance (ESG) credentials. Crowdfunding platforms that support eco-friendly sta...\n",
      "--------------------------------------------------------------------------------\n",
      "<|system|>\n",
      "You are ChatGPT, a large language model trained by OpenAI.\n",
      "<|user|>\n",
      "I'm considering how the community property and common-law marriage frameworks might impact my financial planning and asset management. What are the key differences between these two legal frameworks, and how should I approach optimizing my financial strategy in a community property state?\n",
      "<|assistant|>\n",
      "Community property refers to a legal framework mostly found in select U.S. states, where married couples are considered to jointly own most property and debts acquired during the marriage. In these states, assets and liabilities are typically split 50/50 upon divorce or death. Common-law marriage, on the other hand, is a legal framework that recognizes a couple as married without them having formally registered th...\n",
      "--------------------------------------------------------------------------------\n",
      "<|system|>\n",
      "You are ChatGPT, a large language model trained by OpenAI.\n",
      "<|user|>\n",
      "With economic uncertainty due to a potential recession, what factors should we consider when deciding between taking a lottery prize as a lump sum or an annuity to ensure long-term financial stability?\n",
      "<|assistant|>\n",
      "When faced with the decision of taking a lottery prize as a lump sum or an annuity amidst economic uncertainty, consider factors such as current and projected inflation rates, your current financial needs and obligations, your ability to manage a large sum of money responsibly, potential investment opportunities, tax implications, and your life expectancy. An annuity provides steady income over time, which can mitigate the risk of poor financial management, while a lump sum offers flexibility and pot...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding EOS to train dataset: 100%|██████████| 5400/5400 [00:00<00:00, 45994.94 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 5400/5400 [00:02<00:00, 2044.34 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 5400/5400 [00:00<00:00, 675028.81 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 600/600 [00:00<00:00, 38989.58 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 600/600 [00:00<00:00, 2071.67 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 600/600 [00:00<00:00, 208360.85 examples/s]\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning with SFTTrainer...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4050' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4050/4050 48:56, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.378800</td>\n",
       "      <td>1.315460</td>\n",
       "      <td>1.346846</td>\n",
       "      <td>145519.000000</td>\n",
       "      <td>0.660656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.261500</td>\n",
       "      <td>1.266121</td>\n",
       "      <td>1.264365</td>\n",
       "      <td>291560.000000</td>\n",
       "      <td>0.669053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.245800</td>\n",
       "      <td>1.242430</td>\n",
       "      <td>1.249338</td>\n",
       "      <td>435365.000000</td>\n",
       "      <td>0.672452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.227500</td>\n",
       "      <td>1.228915</td>\n",
       "      <td>1.245777</td>\n",
       "      <td>579310.000000</td>\n",
       "      <td>0.674903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.208100</td>\n",
       "      <td>1.220226</td>\n",
       "      <td>1.229355</td>\n",
       "      <td>723416.000000</td>\n",
       "      <td>0.676087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.218700</td>\n",
       "      <td>1.214479</td>\n",
       "      <td>1.242203</td>\n",
       "      <td>869141.000000</td>\n",
       "      <td>0.677633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.200600</td>\n",
       "      <td>1.205266</td>\n",
       "      <td>1.206777</td>\n",
       "      <td>1016655.000000</td>\n",
       "      <td>0.678714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.163400</td>\n",
       "      <td>1.203429</td>\n",
       "      <td>1.201180</td>\n",
       "      <td>1160557.000000</td>\n",
       "      <td>0.678184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.171000</td>\n",
       "      <td>1.198647</td>\n",
       "      <td>1.197959</td>\n",
       "      <td>1304312.000000</td>\n",
       "      <td>0.679839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.166300</td>\n",
       "      <td>1.195623</td>\n",
       "      <td>1.200099</td>\n",
       "      <td>1450004.000000</td>\n",
       "      <td>0.680850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.149500</td>\n",
       "      <td>1.192691</td>\n",
       "      <td>1.191786</td>\n",
       "      <td>1595043.000000</td>\n",
       "      <td>0.681377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.155300</td>\n",
       "      <td>1.189223</td>\n",
       "      <td>1.174740</td>\n",
       "      <td>1739505.000000</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.149100</td>\n",
       "      <td>1.187521</td>\n",
       "      <td>1.187157</td>\n",
       "      <td>1885663.000000</td>\n",
       "      <td>0.682193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.134900</td>\n",
       "      <td>1.186532</td>\n",
       "      <td>1.160019</td>\n",
       "      <td>2026147.000000</td>\n",
       "      <td>0.682338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.145600</td>\n",
       "      <td>1.184845</td>\n",
       "      <td>1.171073</td>\n",
       "      <td>2170792.000000</td>\n",
       "      <td>0.682741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.130300</td>\n",
       "      <td>1.183630</td>\n",
       "      <td>1.163965</td>\n",
       "      <td>2316777.000000</td>\n",
       "      <td>0.682817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.145500</td>\n",
       "      <td>1.182746</td>\n",
       "      <td>1.162233</td>\n",
       "      <td>2461190.000000</td>\n",
       "      <td>0.683113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.140300</td>\n",
       "      <td>1.181088</td>\n",
       "      <td>1.160706</td>\n",
       "      <td>2606946.000000</td>\n",
       "      <td>0.683713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.138600</td>\n",
       "      <td>1.180225</td>\n",
       "      <td>1.168785</td>\n",
       "      <td>2750796.000000</td>\n",
       "      <td>0.683354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.114100</td>\n",
       "      <td>1.180229</td>\n",
       "      <td>1.154968</td>\n",
       "      <td>2895334.000000</td>\n",
       "      <td>0.683708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.179630</td>\n",
       "      <td>1.155798</td>\n",
       "      <td>3043369.000000</td>\n",
       "      <td>0.683290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.125200</td>\n",
       "      <td>1.179331</td>\n",
       "      <td>1.157257</td>\n",
       "      <td>3187213.000000</td>\n",
       "      <td>0.683616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.138900</td>\n",
       "      <td>1.178711</td>\n",
       "      <td>1.164377</td>\n",
       "      <td>3332697.000000</td>\n",
       "      <td>0.683846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.120300</td>\n",
       "      <td>1.178209</td>\n",
       "      <td>1.159821</td>\n",
       "      <td>3478320.000000</td>\n",
       "      <td>0.683667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.108600</td>\n",
       "      <td>1.178038</td>\n",
       "      <td>1.153877</td>\n",
       "      <td>3623410.000000</td>\n",
       "      <td>0.683793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.111600</td>\n",
       "      <td>1.177485</td>\n",
       "      <td>1.152070</td>\n",
       "      <td>3767831.000000</td>\n",
       "      <td>0.684299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.110200</td>\n",
       "      <td>1.177829</td>\n",
       "      <td>1.150686</td>\n",
       "      <td>3907812.000000</td>\n",
       "      <td>0.684058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.139500</td>\n",
       "      <td>1.177710</td>\n",
       "      <td>1.152376</td>\n",
       "      <td>4051878.000000</td>\n",
       "      <td>0.684201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.111500</td>\n",
       "      <td>1.177570</td>\n",
       "      <td>1.151507</td>\n",
       "      <td>4195261.000000</td>\n",
       "      <td>0.684161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.105700</td>\n",
       "      <td>1.177360</td>\n",
       "      <td>1.149141</td>\n",
       "      <td>4340282.000000</td>\n",
       "      <td>0.684044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.129800</td>\n",
       "      <td>1.177268</td>\n",
       "      <td>1.153437</td>\n",
       "      <td>4484952.000000</td>\n",
       "      <td>0.684324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.118400</td>\n",
       "      <td>1.176994</td>\n",
       "      <td>1.153192</td>\n",
       "      <td>4629554.000000</td>\n",
       "      <td>0.684111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.110500</td>\n",
       "      <td>1.177060</td>\n",
       "      <td>1.151976</td>\n",
       "      <td>4775389.000000</td>\n",
       "      <td>0.683893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.118500</td>\n",
       "      <td>1.176861</td>\n",
       "      <td>1.151345</td>\n",
       "      <td>4924887.000000</td>\n",
       "      <td>0.684156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.121200</td>\n",
       "      <td>1.176887</td>\n",
       "      <td>1.151231</td>\n",
       "      <td>5069299.000000</td>\n",
       "      <td>0.684053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.124300</td>\n",
       "      <td>1.177044</td>\n",
       "      <td>1.151051</td>\n",
       "      <td>5215544.000000</td>\n",
       "      <td>0.683894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.102200</td>\n",
       "      <td>1.176977</td>\n",
       "      <td>1.150003</td>\n",
       "      <td>5361243.000000</td>\n",
       "      <td>0.684190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.176952</td>\n",
       "      <td>1.150239</td>\n",
       "      <td>5505761.000000</td>\n",
       "      <td>0.683892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.125400</td>\n",
       "      <td>1.176892</td>\n",
       "      <td>1.150673</td>\n",
       "      <td>5649338.000000</td>\n",
       "      <td>0.683956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.111400</td>\n",
       "      <td>1.176865</td>\n",
       "      <td>1.150306</td>\n",
       "      <td>5793519.000000</td>\n",
       "      <td>0.684227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Train result: TrainOutput(global_step=4050, training_loss=1.1562512602629484, metrics={'train_runtime': 2937.634, 'train_samples_per_second': 11.029, 'train_steps_per_second': 1.379, 'total_flos': 4.614991318018867e+16, 'train_loss': 1.1562512602629484, 'epoch': 6.0})\n",
      "\n",
      "[DEBUG] Running final evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Final evaluation results: {'eval_loss': 1.1770471334457397, 'eval_runtime': 10.6822, 'eval_samples_per_second': 56.168, 'eval_steps_per_second': 28.084, 'eval_entropy': 1.1511176282167435, 'eval_num_tokens': 5861718.0, 'eval_mean_token_accuracy': 0.6841051942110061, 'epoch': 6.0}\n",
      "\n",
      "Saving final model to /home/models/finetuned_qwen2.5-finance-correct/\n",
      "Fine-tuning done successfully!\n"
     ]
    }
   ],
   "source": [
    "if sft_config.gradient_checkpointing and hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"\\n[DEBUG] Sample preprocessed training strings:\")\n",
    "for i in range(min(3, len(train_dataset))):\n",
    "    text = train_dataset[i][\"text\"]\n",
    "    print(text[:800] + \"...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    # No formatting_func needed since we preprocessed the data\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning with SFTTrainer...\")\n",
    "train_result = trainer.train()\n",
    "print(\"\\n[DEBUG] Train result:\", train_result)\n",
    "\n",
    "print(\"\\n[DEBUG] Running final evaluation...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\n[DEBUG] Final evaluation results:\", eval_results)\n",
    "try:\n",
    "    wandb.log(eval_results)\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] wandb.log failed: {e}\")\n",
    "\n",
    "final_model_dir = \"/home/models/finetuned_qwen2.5-finance-correct/\"\n",
    "os.makedirs(final_model_dir, exist_ok=True)\n",
    "print(f\"\\nSaving final model to {final_model_dir}\")\n",
    "trainer.save_model(final_model_dir)\n",
    "tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "print(\"Fine-tuning done successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccff49a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in to Hugging Face...\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face with token\n",
    "print(\"Logging in to Hugging Face...\")\n",
    "HF_TOKEN = \"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\"  # don't worry, this is a test token; you can't use it to do anything ;)\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592371ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to push model from: /home/models/finetuned_qwen2.5-finance-correct\n",
      "Target repository: sohv/finetuned-qwen2.5-1.5b-finance-correct\n",
      "Pushing model to Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :   0%|          | 1.17MB / 6.17GB,  834kB/s  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 2.34MB / 6.17GB, 1.30MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 3.51MB / 6.17GB, 1.76MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 5.85MB / 6.17GB, 2.66MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 11.7MB / 6.17GB, 4.88MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 17.5MB / 6.17GB, 6.75MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   0%|          | 24.6MB / 6.17GB, 8.78MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   1%|          | 37.5MB / 6.17GB, 12.5MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   1%|          | 49.2MB / 6.17GB, 15.4MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   1%|          | 72.6MB / 6.17GB, 21.4MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   2%|▏         | 94.8MB / 6.17GB, 26.3MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   2%|▏         |  112MB / 6.17GB, 29.6MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   2%|▏         |  135MB / 6.17GB, 33.6MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   3%|▎         |  172MB / 6.17GB, 41.0MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   3%|▎         |  201MB / 6.17GB, 45.8MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   4%|▍         |  236MB / 6.17GB, 51.4MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   4%|▍         |  262MB / 6.17GB, 54.6MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   5%|▍         |  305MB / 6.17GB, 61.0MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   6%|▌         |  350MB / 6.17GB, 67.4MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   6%|▋         |  391MB / 6.17GB, 72.5MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   7%|▋         |  435MB / 6.17GB, 77.6MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   8%|▊         |  480MB / 6.17GB, 82.8MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   8%|▊         |  521MB / 6.17GB, 86.9MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :   9%|▉         |  572MB / 6.17GB, 92.3MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  10%|▉         |  611MB / 6.17GB, 95.5MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  10%|█         |  641MB / 6.17GB, 97.2MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  11%|█         |  693MB / 6.17GB,  102MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  12%|█▏        |  719MB / 6.17GB,  103MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  12%|█▏        |  750MB / 6.17GB,  104MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  13%|█▎        |  786MB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  13%|█▎        |  828MB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  14%|█▍        |  867MB / 6.17GB,  111MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  15%|█▍        |  912MB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  15%|█▌        |  942MB / 6.17GB,  115MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  16%|█▌        |  983MB / 6.17GB,  117MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  16%|█▋        | 1.01GB / 6.17GB,  117MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  17%|█▋        | 1.03GB / 6.17GB,  117MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  17%|█▋        | 1.07GB / 6.17GB,  119MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  18%|█▊        | 1.10GB / 6.17GB,  119MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  18%|█▊        | 1.13GB / 6.17GB,  120MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  19%|█▊        | 1.16GB / 6.17GB,  120MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  19%|█▉        | 1.19GB / 6.17GB,  121MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  20%|█▉        | 1.22GB / 6.17GB,  122MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  21%|██        | 1.27GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  21%|██▏       | 1.31GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  22%|██▏       | 1.35GB / 6.17GB,  132MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  22%|██▏       | 1.38GB / 6.17GB,  135MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  23%|██▎       | 1.42GB / 6.17GB,  139MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  24%|██▎       | 1.46GB / 6.17GB,  143MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  24%|██▍       | 1.50GB / 6.17GB,  147MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  25%|██▍       | 1.54GB / 6.17GB,  151MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  25%|██▌       | 1.57GB / 6.17GB,  154MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  26%|██▌       | 1.62GB / 6.17GB,  158MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  27%|██▋       | 1.64GB / 6.17GB,  161MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  27%|██▋       | 1.68GB / 6.17GB,  164MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  28%|██▊       | 1.72GB / 6.17GB,  167MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  28%|██▊       | 1.76GB / 6.17GB,  170MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  29%|██▉       | 1.78GB / 6.17GB,  172MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  29%|██▉       | 1.81GB / 6.17GB,  174MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  30%|██▉       | 1.84GB / 6.17GB,  176MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  30%|███       | 1.88GB / 6.17GB,  177MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  31%|███       | 1.91GB / 6.17GB,  178MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  31%|███▏      | 1.94GB / 6.17GB,  180MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  32%|███▏      | 1.98GB / 6.17GB,  181MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  33%|███▎      | 2.02GB / 6.17GB,  181MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  33%|███▎      | 2.06GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  34%|███▍      | 2.08GB / 6.17GB,  181MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  34%|███▍      | 2.12GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  35%|███▌      | 2.17GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  36%|███▌      | 2.21GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  36%|███▋      | 2.24GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  37%|███▋      | 2.29GB / 6.17GB,  182MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  38%|███▊      | 2.32GB / 6.17GB,  180MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  38%|███▊      | 2.35GB / 6.17GB,  180MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  39%|███▊      | 2.39GB / 6.17GB,  178MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  39%|███▉      | 2.43GB / 6.17GB,  178MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  40%|███▉      | 2.46GB / 6.17GB,  178MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  40%|███▉      | 2.47GB / 6.17GB,  174MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  40%|████      | 2.48GB / 6.17GB,  173MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  41%|████      | 2.51GB / 6.17GB,  172MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  41%|████      | 2.53GB / 6.17GB,  171MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  41%|████▏     | 2.56GB / 6.17GB,  170MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  42%|████▏     | 2.57GB / 6.17GB,  167MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  42%|████▏     | 2.61GB / 6.17GB,  166MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  43%|████▎     | 2.63GB / 6.17GB,  166MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  43%|████▎     | 2.66GB / 6.17GB,  165MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  44%|████▎     | 2.69GB / 6.17GB,  165MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  44%|████▍     | 2.71GB / 6.17GB,  165MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  44%|████▍     | 2.73GB / 6.17GB,  163MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  45%|████▍     | 2.75GB / 6.17GB,  162MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  45%|████▍     | 2.76GB / 6.17GB,  160MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  45%|████▌     | 2.78GB / 6.17GB,  160MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  45%|████▌     | 2.80GB / 6.17GB,  158MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  46%|████▌     | 2.83GB / 6.17GB,  157MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  46%|████▌     | 2.85GB / 6.17GB,  154MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  47%|████▋     | 2.87GB / 6.17GB,  153MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  47%|████▋     | 2.89GB / 6.17GB,  152MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  47%|████▋     | 2.93GB / 6.17GB,  152MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  48%|████▊     | 2.96GB / 6.17GB,  151MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  48%|████▊     | 2.99GB / 6.17GB,  150MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  49%|████▉     | 3.01GB / 6.17GB,  149MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  49%|████▉     | 3.04GB / 6.17GB,  147MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  50%|████▉     | 3.07GB / 6.17GB,  147MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  50%|████▉     | 3.09GB / 6.17GB,  144MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  50%|█████     | 3.11GB / 6.17GB,  144MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  51%|█████     | 3.12GB / 6.17GB,  141MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  51%|█████     | 3.15GB / 6.17GB,  141MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  51%|█████     | 3.16GB / 6.17GB,  138MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  52%|█████▏    | 3.20GB / 6.17GB,  139MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  52%|█████▏    | 3.22GB / 6.17GB,  139MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  53%|█████▎    | 3.26GB / 6.17GB,  139MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  53%|█████▎    | 3.30GB / 6.17GB,  140MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  54%|█████▍    | 3.34GB / 6.17GB,  140MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  55%|█████▍    | 3.38GB / 6.17GB,  141MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  55%|█████▌    | 3.41GB / 6.17GB,  140MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  56%|█████▌    | 3.45GB / 6.17GB,  140MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  56%|█████▋    | 3.48GB / 6.17GB,  139MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  57%|█████▋    | 3.51GB / 6.17GB,  140MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  57%|█████▋    | 3.53GB / 6.17GB,  138MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  57%|█████▋    | 3.55GB / 6.17GB,  136MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  58%|█████▊    | 3.57GB / 6.17GB,  134MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  58%|█████▊    | 3.58GB / 6.17GB,  131MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  58%|█████▊    | 3.59GB / 6.17GB,  128MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  59%|█████▊    | 3.62GB / 6.17GB,  127MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  59%|█████▉    | 3.65GB / 6.17GB,  127MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  59%|█████▉    | 3.67GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  60%|██████    | 3.71GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  61%|██████    | 3.74GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  61%|██████    | 3.76GB / 6.17GB,  127MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  61%|██████▏   | 3.79GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  62%|██████▏   | 3.83GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  62%|██████▏   | 3.86GB / 6.17GB,  130MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  63%|██████▎   | 3.88GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  63%|██████▎   | 3.90GB / 6.17GB,  130MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  63%|██████▎   | 3.92GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  64%|██████▎   | 3.93GB / 6.17GB,  128MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  64%|██████▍   | 3.96GB / 6.17GB,  127MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  64%|██████▍   | 3.97GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  65%|██████▍   | 3.99GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  65%|██████▍   | 4.01GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  65%|██████▌   | 4.03GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  66%|██████▌   | 4.07GB / 6.17GB,  128MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  66%|██████▋   | 4.09GB / 6.17GB,  128MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  67%|██████▋   | 4.13GB / 6.17GB,  130MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  67%|██████▋   | 4.16GB / 6.17GB,  131MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  68%|██████▊   | 4.19GB / 6.17GB,  132MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  68%|██████▊   | 4.22GB / 6.17GB,  132MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  69%|██████▊   | 4.24GB / 6.17GB,  132MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  69%|██████▉   | 4.25GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  69%|██████▉   | 4.27GB / 6.17GB,  129MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  69%|██████▉   | 4.29GB / 6.17GB,  127MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  70%|██████▉   | 4.30GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  70%|██████▉   | 4.32GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  70%|███████   | 4.34GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  71%|███████   | 4.36GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  71%|███████   | 4.38GB / 6.17GB,  125MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  71%|███████▏  | 4.40GB / 6.17GB,  126MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  72%|███████▏  | 4.42GB / 6.17GB,  124MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  72%|███████▏  | 4.43GB / 6.17GB,  124MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  72%|███████▏  | 4.45GB / 6.17GB,  123MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  73%|███████▎  | 4.48GB / 6.17GB,  123MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  73%|███████▎  | 4.50GB / 6.17GB,  121MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  73%|███████▎  | 4.52GB / 6.17GB,  119MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  74%|███████▎  | 4.55GB / 6.17GB,  119MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  74%|███████▍  | 4.57GB / 6.17GB,  116MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  74%|███████▍  | 4.59GB / 6.17GB,  115MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  75%|███████▍  | 4.61GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  75%|███████▌  | 4.64GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  75%|███████▌  | 4.65GB / 6.17GB,  112MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  76%|███████▌  | 4.67GB / 6.17GB,  111MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  76%|███████▌  | 4.69GB / 6.17GB,  112MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  76%|███████▌  | 4.69GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  76%|███████▌  | 4.71GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  76%|███████▋  | 4.72GB / 6.17GB,  111MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  77%|███████▋  | 4.74GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  77%|███████▋  | 4.76GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  77%|███████▋  | 4.78GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  78%|███████▊  | 4.81GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  78%|███████▊  | 4.84GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  79%|███████▉  | 4.86GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  79%|███████▉  | 4.89GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  80%|███████▉  | 4.92GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  80%|████████  | 4.95GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  80%|████████  | 4.97GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  81%|████████  | 4.98GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  81%|████████  | 5.00GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  81%|████████  | 5.01GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  82%|████████▏ | 5.04GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  82%|████████▏ | 5.05GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  82%|████████▏ | 5.07GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  82%|████████▏ | 5.09GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  83%|████████▎ | 5.12GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  83%|████████▎ | 5.14GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  84%|████████▎ | 5.16GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  84%|████████▍ | 5.19GB / 6.17GB,  104MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  84%|████████▍ | 5.21GB / 6.17GB,  103MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  85%|████████▍ | 5.25GB / 6.17GB,  103MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  85%|████████▌ | 5.27GB / 6.17GB,  103MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  86%|████████▌ | 5.29GB / 6.17GB,  103MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  86%|████████▌ | 5.31GB / 6.17GB,  104MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  86%|████████▋ | 5.34GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  87%|████████▋ | 5.37GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  87%|████████▋ | 5.40GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  88%|████████▊ | 5.42GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  88%|████████▊ | 5.45GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  89%|████████▊ | 5.47GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  89%|████████▉ | 5.49GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  89%|████████▉ | 5.52GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  90%|████████▉ | 5.54GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  90%|████████▉ | 5.55GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  90%|█████████ | 5.56GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  90%|█████████ | 5.58GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  90%|█████████ | 5.59GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  91%|█████████ | 5.60GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  91%|█████████ | 5.61GB / 6.17GB,  104MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  91%|█████████ | 5.63GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  92%|█████████▏| 5.65GB / 6.17GB,  105MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  92%|█████████▏| 5.69GB / 6.17GB,  106MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  93%|█████████▎| 5.73GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  93%|█████████▎| 5.75GB / 6.17GB,  107MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  94%|█████████▎| 5.78GB / 6.17GB,  109MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  94%|█████████▍| 5.82GB / 6.17GB,  111MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  95%|█████████▍| 5.84GB / 6.17GB,  112MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  95%|█████████▌| 5.87GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  96%|█████████▌| 5.90GB / 6.17GB,  115MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  96%|█████████▌| 5.91GB / 6.17GB,  115MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  96%|█████████▌| 5.93GB / 6.17GB,  115MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  96%|█████████▌| 5.94GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  97%|█████████▋| 5.97GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  97%|█████████▋| 5.99GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  97%|█████████▋| 6.01GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  98%|█████████▊| 6.05GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  99%|█████████▊| 6.09GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  99%|█████████▉| 6.11GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  99%|█████████▉| 6.12GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                :  99%|█████████▉| 6.14GB / 6.17GB,  114MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                : 100%|█████████▉| 6.15GB / 6.17GB,  113MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                : 100%|█████████▉| 6.15GB / 6.17GB,  112MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (0 / 2)                : 100%|█████████▉| 6.16GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (1 / 2)                : 100%|█████████▉| 6.17GB / 6.17GB,  110MB/s  \n",
      "\u001b[A\n",
      "\n",
      "Processing Files (1 / 2)                : 100%|█████████▉| 6.17GB / 6.17GB,  108MB/s  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Processing Files (2 / 2)                : 100%|██████████| 6.17GB / 6.17GB,  102MB/s  \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Processing Files (2 / 2)                : 100%|██████████| 6.17GB / 6.17GB, 88.4MB/s  \n",
      "New Data Upload                         : 100%|██████████| 6.17GB / 6.17GB, 88.4MB/s  \n",
      "  ...8h/model-00002-of-00002.safetensors: 100%|██████████| 1.18GB / 1.18GB            \n",
      "  ...8h/model-00001-of-00002.safetensors: 100%|██████████| 5.00GB / 5.00GB            \n",
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 11.4MB / 11.4MB, 14.3MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 11.4MB / 11.4MB, 4.39MB/s  \n",
      "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
      "  /tmp/tmpbrh9vxgi/tokenizer.json       : 100%|██████████| 11.4MB / 11.4MB            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully pushed to: https://huggingface.co/sohv/finetuned-qwen2.5-1.5b-finance-correct\n"
     ]
    }
   ],
   "source": [
    "# Model information\n",
    "model_path = \"/home/models/finetuned_qwen2.5-finance-correct\"\n",
    "repo_name = \"sohv/finetuned-qwen2.5-1.5b-finance-correct\"\n",
    "\n",
    "print(f\"Preparing to push model from: {model_path}\")\n",
    "print(f\"Target repository: {repo_name}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Push to hub\n",
    "print(\"Pushing model to Hugging Face Hub...\")\n",
    "model.push_to_hub(repo_name, private=False)  # Set private=True if you want a private repo\n",
    "tokenizer.push_to_hub(repo_name, private=False)\n",
    "\n",
    "print(f\"Model successfully pushed to: https://huggingface.co/{repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
